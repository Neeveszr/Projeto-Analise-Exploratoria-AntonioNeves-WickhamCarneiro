# ğŸ“¦ Projeto de AnÃ¡lise ExploratÃ³ria - Olist E-Commerce
Impulsionado pela facilidade de compra e diversidade de produtos, o comÃ©rcio eletrÃ´nico brasileiro estÃ¡ bastante presente no dia a dia da populaÃ§Ã£o, em contrapartida, apresenta vÃ¡rios desafios logÃ­sticos significativos, como atrasos na entrega, inconsistÃªncias nos cadastros e grande variaÃ§Ã£o de caracterÃ­sticas de produtos. Essas imperfeiÃ§Ãµes sÃ£o tÃ­picas de um ambiente real de comercio online.
Diante desse cenÃ¡rio, surge o problema real tratado nesse trabalho: O que afeta a experiÃªncia e satisfaÃ§Ã£o do cliente no e-commerce brasileiro?

## ğŸ‘¥ Integrantes
- AntÃ´nio Neves Aguiar Neto
- Wickham Carneiro Pereira

---

## ğŸ”— Base de Dados Utilizada
O projeto utiliza parte do conjunto de dados pÃºblicos da **Olist**, disponibilizado originalmente no Kaggle:

**Link da base completa:**  
https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce/data

Datasets utilizados no projeto:
- `olist_orders_dataset.csv`  
- `olist_order_items_dataset.csv`  
- `olist_products_dataset.csv`

Olist_order_items_dataset â€“ Itens vendidos em cada pedido
Olist_orders_dataset â€“ InformaÃ§Ãµes dos pedidos
Olist_products_dataset â€“ InformaÃ§Ãµes dos produtos

---

## ğŸ¯ Objetivo do Projeto
Aplicar o ciclo de vida da CiÃªncia de Dados para descobrir o que afeta a experiÃªncia e satisfaÃ§Ã£o do cliente no e-commerce brasileiro, investigando os padrÃµes que influenciam:

â— Atrasos de entrega
â— Baixa ou alta satisfaÃ§Ã£o
â— DiferenÃ§as de preÃ§o e frete
â— Categorias de produtos problemÃ¡ticas
â— VariaÃ§Ãµes no tempo de processamento e envio


O objetivo final foi construir um dataset limpo, padronizado e enriquecido, capaz de gerar insights relevantes sobre desempenho logÃ­stico e experiÃªncia do cliente.

---

## ğŸ› ï¸ DescriÃ§Ã£o do Processo de Tratamento dos Dados

O prÃ©-processamento dos dados foi realizado seguindo uma sequÃªncia estruturada de etapas para garantir consistÃªncia, qualidade e confiabilidade das anÃ¡lises. As principais fases foram:

### **1. Carregamento e ExploraÃ§Ã£o Inicial**
Iniciamos com a inspeÃ§Ã£o das bases utilizando `df.head()`, `df.info()` e `df.describe()`.  
Essa etapa permitiu identificar tipos de dados, presenÃ§a de valores ausentes, estatÃ­sticas descritivas e possÃ­veis problemas iniciais.

### **2. IdentificaÃ§Ã£o dos Valores Ausentes**
Com o comando `df.isnull().sum()`, contabilizamos a quantidade de valores ausentes em cada coluna.  
Isso permitiu definir quais atributos precisavam de imputaÃ§Ã£o ou tratamento especÃ­fico.

### **3. Tratamento dos Valores Ausentes**
- VariÃ¡veis numÃ©ricas receberam **imputaÃ§Ã£o pela mediana por categoria**, garantindo coerÃªncia com o comportamento dos produtos.  
- Colunas categÃ³ricas tiveram seus valores ausentes substituÃ­dos por `"desconhecido"`.

### **4. CorreÃ§Ã£o de InconsistÃªncias**
- Valores impossÃ­veis, como **pesos igual a zero ou negativos**, foram substituÃ­dos pela mediana da respectiva categoria de produto.  
- Realizamos padronizaÃ§Ã£o textual (`str.lower()` + `str.strip()`) para evitar categorias duplicadas devido a diferenÃ§as de maiÃºsculas/minÃºsculas ou espaÃ§os extras.

### **5. CodificaÃ§Ã£o das VariÃ¡veis CategÃ³ricas**
Aplicamos **One-Hot Encoding** (`pd.get_dummies`) na coluna `order_status`, permitindo que os modelos e anÃ¡lises futuras trabalhem com variÃ¡veis categÃ³ricas de forma numÃ©rica e interpretÃ¡vel.

### **6. NormalizaÃ§Ã£o / PadronizaÃ§Ã£o das VariÃ¡veis NumÃ©ricas**
Utilizamos o **StandardScaler** para padronizar atributos numÃ©ricos, garantindo escalas equivalentes entre variÃ¡veis e evitando distorÃ§Ãµes em anÃ¡lises que dependem de magnitude.

### **7. CriaÃ§Ã£o de Novas Features (Feature Engineering)**
Foram criados atributos que enriquecem a anÃ¡lise logÃ­stica:
- **Tempo de entrega (delivery_delay_days)** â€“ atraso/adiantamento em dias  
- **Atraso binÃ¡rio (is_late_delivery)** â€“ indicador de atraso  
- **Densidade do produto**  
- **Volume do produto**  
- **Custo logÃ­stico por peso (freight_per_kg)**

Essas features permitiram compreender melhor o comportamento logÃ­stico e identificar relaÃ§Ãµes nÃ£o visÃ­veis nas colunas originais.

---

## ğŸš§ Principais Desafios Encontrados
- Alta ausÃªncia de dados no dataset de produtos  
- Peso e medidas com valores inconsistentes  
- VariÃ¡veis de data no formato texto  
- Necessidade de integrar trÃªs bases diferentes via merge  
- Outliers legÃ­timos que nÃ£o podiam ser removidos  
- DiferenÃ§as de categoria causadas por erros de escrita

---

## ğŸ“Œ Principais ConclusÃµes

- **Atrasos nÃ£o dependem apenas da transportadora:** o tempo de processamento do vendedor Ã© um fator crucial.  
- **Peso e dimensÃµes influenciam diretamente o frete**, com correlaÃ§Ã£o clara entre eles.  
- **A maioria dos pedidos Ã© entregue dentro do prazo**, demonstrando boa eficiÃªncia logÃ­stica.  
- **A limpeza dos dados foi essencial** para corrigir distorÃ§Ãµes, como pesos invÃ¡lidos e categorias duplicadas.  
- As features criadas permitiram **identificar padrÃµes logÃ­sticos profundos**, como relaÃ§Ã£o entre atraso Ã— processamento e custo logÃ­stico Ã— peso.  
- Produtos maiores e mais pesados apresentam comportamento logÃ­stico completamente diferente de produtos pequenos.

---

